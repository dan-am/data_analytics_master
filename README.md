# Patientensegmentierung â€“ Analyseprojekt

## ProjektÃ¼bersicht
Dieses Projekt implementiert einen umfassenden Data-Analytics-Workflow zur Patientensegmentierung unter Verwendung des [Patient Segmentation Dataset von Kaggle](https://www.kaggle.com/datasets/nudratabbas/patient-segmentation-data).

## ğŸ“š Ressourcen

### Datensatz-Empfehlungen
Auf der Suche nach interessanten DatensÃ¤tzen fÃ¼r Ihre Seminararbeit? Unser umfassender Leitfaden hilft weiter:

**[Datensatz-Empfehlungen](dataset_recommendations.md)** â€“ Kuratierte DatensÃ¤tze fÃ¼r:
- ğŸ” Clustering-Analyse
- ğŸ›’ Warenkorbanalyse
- ğŸ’° Finanzdaten & KYC-Analyse
- ğŸ¯ Klassifikationsaufgaben

**[SchnellÃ¼bersicht](DATASETS_QUICK_REFERENCE.md)** â€“ Kompakte Zusammenfassung der wichtigsten DatensÃ¤tze.

## Data-Science-Lebenszyklus

Dieses Projekt folgt einem strukturierten Ansatz basierend auf dem Data-Science-Lebenszyklus:

### Phase 1: GeschÃ¤ftsverstÃ¤ndnis
**Ziel:** GeschÃ¤ftsproblem und Projektziele definieren.
- **Ordner:** `1_business_understanding/`
- **Zweck:** Anforderungen der Patientensegmentierung fÃ¼r Gesundheitsdienstleister verstehen
- **Ergebnisse:** Problemdefinition, Erfolgskriterien, Projektcharta

### Phase 2: Datenanschaffung
**Ziel:** Relevante Daten sammeln und speichern.
- **Ordner:** `2_data_acquisition/`
- **Zweck:** Patientensegmentierungs-Datensatz herunterladen und organisieren
- **Ergebnisse:** Rohdaten, Datenquellen-Dokumentation, Download-Skripte

### Phase 3: Datenvorbereitung
**Ziel:** Daten bereinigen und vorverarbeiten.
- **Ordner:** `3_data_preparation/`
- **Zweck:** Fehlende Werte, AusreiÃŸer und DatenqualitÃ¤tsprobleme behandeln
- **Ergebnisse:** Bereinigte DatensÃ¤tze, DatenqualitÃ¤tsberichte, Vorverarbeitungsskripte

### Phase 4: Explorative Datenanalyse (EDA)
**Ziel:** Datenmuster und ZusammenhÃ¤nge verstehen.
- **Ordner:** `4_exploratory_analysis/`
- **Zweck:** Verteilungen, Korrelationen und wichtige Erkenntnisse visualisieren
- **Ergebnisse:** EDA-Notebooks, Visualisierungsberichte, statistische Zusammenfassungen

### Phase 5: Feature Engineering
**Ziel:** Relevante Features erstellen und auswÃ¤hlen.
- **Ordner:** `5_feature_engineering/`
- **Zweck:** Features fÃ¼r Patientensegmentierungsmodelle entwickeln
- **Ergebnisse:** Feature-Erstellungsskripte, Feature-Selektionsanalyse

### Phase 6: Modellierung
**Ziel:** Machine-Learning-Modelle erstellen und trainieren.
- **Ordner:** `6_modeling/`
- **Zweck:** Clustering-/Klassifikationsmodelle fÃ¼r Patientensegmentierung entwickeln
- **Ergebnisse:** Trainierte Modelle, Trainingsskripte, Hyperparameter-Tuning-Ergebnisse

### Phase 7: Evaluation
**Ziel:** Modellleistung bewerten.
- **Ordner:** `7_evaluation/`
- **Zweck:** SegmentierungsqualitÃ¤t und Modellmetriken evaluieren
- **Ergebnisse:** Evaluationsberichte, Leistungsmetriken, Modellvergleich

### Phase 8: Deployment
**Ziel:** Produktionsbereitstellung vorbereiten.
- **Ordner:** `8_deployment/`
- **Zweck:** Deployment-Strategie dokumentieren und Inferenz-Skripte erstellen
- **Ergebnisse:** Deployment-Leitfaden, API-Spezifikationen, Monitoring-Plan

## Projektstruktur

```
data_analytics_master/
â”œâ”€â”€ README.md                          # Diese Datei
â”œâ”€â”€ requirements.txt                   # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ 1_business_understanding/          # GeschÃ¤ftsproblem-Definition
â”‚   â”œâ”€â”€ project_charter.md
â”‚   â””â”€â”€ success_criteria.md
â”œâ”€â”€ 2_data_acquisition/                # Datensammlung
â”‚   â”œâ”€â”€ raw_data/                      # Originaldaten (gitignored)
â”‚   â”œâ”€â”€ processed_data/                # Verarbeitete Daten (gitignored)
â”‚   â”œâ”€â”€ data_sources/                  # Datenquellen-Dokumentation
â”‚   â””â”€â”€ download_data.py               # Download-Skript
â”œâ”€â”€ 3_data_preparation/                # Datenbereinigung
â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”œâ”€â”€ data_validation.py
â”‚   â””â”€â”€ preprocessing_pipeline.py
â”œâ”€â”€ 4_exploratory_analysis/            # EDA
â”‚   â”œâ”€â”€ eda_notebook.ipynb
â”‚   â”œâ”€â”€ statistical_analysis.py
â”‚   â””â”€â”€ visualization.py
â”œâ”€â”€ 5_feature_engineering/             # Feature-Erstellung
â”‚   â”œâ”€â”€ feature_creation.py
â”‚   â”œâ”€â”€ feature_selection.py
â”‚   â””â”€â”€ feature_engineering_pipeline.py
â”œâ”€â”€ 6_modeling/                        # Modellentwicklung
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ hyperparameter_tuning.py
â”‚   â””â”€â”€ clustering_models.py
â”œâ”€â”€ 7_evaluation/                      # Modellevaluation
â”‚   â”œâ”€â”€ evaluate_model.py
â”‚   â”œâ”€â”€ performance_metrics.py
â”‚   â””â”€â”€ model_comparison.py
â”œâ”€â”€ 8_deployment/                      # Deployment
â”‚   â”œâ”€â”€ deployment_guide.md
â”‚   â”œâ”€â”€ inference_script.py
â”‚   â””â”€â”€ api_documentation.md
â”œâ”€â”€ notebooks/                         # Jupyter-Notebooks
â”œâ”€â”€ reports/                           # Generierte Analyseberichte
â”œâ”€â”€ scripts/                           # Hilfsskripte
â”œâ”€â”€ models/                            # Gespeicherte Modelle (gitignored)
â””â”€â”€ references/                        # Referenzmaterialien
```

## Erste Schritte

### Voraussetzungen
- Python 3.8+
- Kaggle-Konto fÃ¼r den Daten-Download
- BenÃ¶tigte Python-Pakete (siehe requirements.txt)

### Installation

1. Repository klonen:
```bash
git clone https://github.com/dan-am/data_analytics_master.git
cd data_analytics_master
```

2. AbhÃ¤ngigkeiten installieren:
```bash
pip install -r requirements.txt
```

3. Kaggle-API-Zugangsdaten einrichten:
   - Kaggle-Konto erstellen unter https://www.kaggle.com
   - Kontoeinstellungen â†’ API â†’ Neuen API-Token erstellen
   - Die heruntergeladene `kaggle.json` in `~/.kaggle/` ablegen

4. Datensatz herunterladen:
```bash
python 2_data_acquisition/download_data.py
```

### Verwendung

Die Phasen der Reihe nach durcharbeiten:

1. **GeschÃ¤ftsverstÃ¤ndnis:** Dokumentation in `1_business_understanding/` lesen
2. **Daten beschaffen:** Download-Skript in `2_data_acquisition/` ausfÃ¼hren
3. **Daten vorbereiten:** Bereinigungsskripte in `3_data_preparation/` ausfÃ¼hren
4. **Daten explorieren:** EDA-Notebooks in `4_exploratory_analysis/` ausfÃ¼hren
5. **Features erstellen:** Feature-Skripte in `5_feature_engineering/` nutzen
6. **Modelle erstellen:** Modelle mit Skripten in `6_modeling/` trainieren
7. **Evaluieren:** Leistung mit Skripten in `7_evaluation/` bewerten
8. **Bereitstellen:** Deployment-Leitfaden in `8_deployment/` befolgen

## Datensatz-Informationen

**Quelle:** [Kaggle â€“ Patient Segmentation Data](https://www.kaggle.com/datasets/nudratabbas/patient-segmentation-data)

**Beschreibung:** Dieser Datensatz enthÃ¤lt Patienteninformationen fÃ¼r Segmentierungsanalysen und eignet sich fÃ¼r Healthcare-Analytics und Patienten-Clustering.

## Mitwirken

BeitrÃ¤ge sind willkommen! Bitte die bestehende Projektstruktur und die Phasen des Data-Science-Lebenszyklus einhalten.

## Lizenz

Dieses Projekt ist Teil des DAMI01/DATA01 Data Analytics Masterstudiengangs.

## Kontakt

Bei Fragen oder Problemen bitte ein Issue im Repository erstellen.
